---
title: "Hour a Day: AI - Day 2 - Starting off with a plan"
date: 2025-03-28T00:00:00-04:00
categories:
  - "Hour a Day: AI"
tags:
  - ai
---

In yesterday's post, I got all the blog's dependencies updated and the blog building with the help of my new best friend Claude + Aider. 

It did take a substantial amount of time to format the blog though with all the prompts involved and manually copying and pasting from the history file.

So I think the first thing to do as part of this adventure is make writing about the adventure a lot easier! Let's automate it!

---

## The Initial Requirements doc

I have heard a lot that when working with generative AI it's best to have clear requirements defined in a file that can be used as a general prompt throughout the building process. Why lose all the valuable information when the chat session ends?

So I started with this small requirements doc, not trying too hard to get details finalized yet.

> # High Level Goal for "llm-history-to-post"
> 
> llm-history-to-post is an application that will parse llm chat logs and create blog post templates based on user input.
> 
> # Requirements
> * The application should interact over the cli
> * The application should parse a ".aider.chat.history.md" into an in memory collection of the user entered prompt and the llm output response
>    * This parsed input should be logically organized by day
> * When the application is run the user should be able to select which singular day they would like to process
> * After the user has selected the desired day, the user should be presented a list of the parsed prompts where they can choose to select which prompts / responses to populate into the end result
>     * The user should be able to select any number of prompts to process while skipping others.
>         * This should be a multi select list offered like SharPrompt
>     * The user should select the prompt response pair by only previewing the prompt itself.
> * Once selected, each prompt response pair should be represented to the user and then asked if verdict was pass or failure. This input should make it into the blog.
> * Once all the questions have been answered the application should output a new blog post that was constructed from a source template

So I switched over to aider's [ask mode](https://aider.chat/docs/usage/modes.html) and asked it for feedback on these requirements

> **Prompt:**
>
> can you look at requirements.md and help me fine tune the individual asks to better suit feeding into aider for implementation?
 

> **Response:**
>
> > llm-history-to-post/requirements.md  
> > Add file to the chat? (Y)es/(N)o/(D)on't ask again [Yes]: y
> 
> After reviewing the requirements.md file, I can help refine the requirements to make them more suitable for implementation with aider. Here's my analysis and suggestions:
> 
> ## Refined Requirements for llm-history-to-post
> 
> 1. **CLI Interface**
>     - This is clear, but we could specify the command structure, e.g., `llm-history-to-post [options] [path-to-history-file]`
>     - Consider adding optional flags like `--output-dir` or `--template-path`
> 
> 2. **Parsing Chat History**
>     - The format of ".aider.chat.history.md" should be more explicitly defined
>     - Specify how to identify user prompts vs LLM responses in the file
>     - Define what "logically organized by day" means - are there date headers in the file?
> 
> 3. **Day Selection**
>     - Specify the UI for day selection (numbered list?)
>     - What if there's only one day in the history?
>     - What format should dates be displayed in?
> 
> 4. **Prompt Selection**
>     - The multi-select with SharpPrompt is clear
>     - Specify how much of each prompt to preview (first N characters?)
>     - Should there be an option to view the full prompt before selecting?
> 
> 5. **Pass/Failure Verdict**
>     - Clarify the format for collecting this information (Y/N prompt? Multiple choice?)
>     - Define what "pass" and "failure" mean in this context
>     - Specify how this verdict should be formatted in the blog post
> 
> 6. **Blog Post Generation**
>     - The "source template" is mentioned but not defined - specify the template format
>     - Define the output format (Markdown? HTML?)
>     - Specify where the generated blog post should be saved
>     - Consider adding metadata like title, date, tags
> 
> 7. **Error Handling**
>     - Add requirements for handling invalid input files
>     - Specify behavior when user cancels mid-process
>     - Define how to handle empty selections
> 
> 8. **Additional Considerations**
>     - Add ability to edit prompts/responses before inclusion in the blog
>     - Consider pagination for large history files
>     - Add option to save selection state for resuming later
> 
> By making these requirements more specific and detailed, it will be easier for aider to generate accurate implementation code that meets your needs precisely.
> 
> Would you like me to rewrite the entire requirements document with these refinements, or would you prefer to focus on specific areas?
>
> Tokens: 1.0k sent, 497 received. Cost: $0.01 message, $0.01 session.
>
>
> ^C again to exit

**Verdict:** ✅ Exactly what I was looking for! It had questions that I knew I hadn't specified but I wanted to see if it understood the general idea before getting more technical.

## Taking Suggestions!

> **Prompt:**
>
> yes please help refine the requirements. you can look at 2025-03-27-hadai-day-1.md as the source to answer some of your questions about formatting.
 
> **Response:**
>
> > content/post/2025/03/2025-03-27-hadai-day-1.md  
> > Add file to the chat? (Y)es/(N)o/(D)on't ask again [Yes]: y
> 
> # Refined Requirements for "llm-history-to-post"
> 
> ## High Level Goal
> llm-history-to-post is an application that parses LLM chat logs and creates blog post templates based on user input, following the format seen in the example blog post.
> 
> ## Detailed Requirements
> 
> ### CLI Interface
> * The application should be invoked via command line: `llm-history-to-post [path-to-history-file]`
> * Optional flags:
>     * `--output-dir`: Directory to save the generated blog post (default: current directory)
>     * `--template-path`: Path to a custom blog post template (default: built-in template)
> 
> ### Parsing Chat History
> * Parse a ".aider.chat.history.md" file into an in-memory collection of user prompts and LLM responses
> * The file format contains sections with:
>     * User prompts prefixed with "> **Prompt:**"
>     * LLM responses prefixed with "> **Response:**"
> * Group these prompt-response pairs by day based on timestamps in the file
> * Each day should be identified by a date in the format YYYY-MM-DD
> 
> ### Day Selection
> * Present the user with a numbered list of available days found in the history file
> * Display dates in YYYY-MM-DD format
> * If only one day exists, automatically select it
> * Allow user to select a single day to process
> 
> ### Prompt Selection
> * After day selection, display a multi-select list (using SharpPrompt or similar) of all prompts from that day
> * Show the first 100 characters of each prompt as a preview, with "..." if truncated
> * Allow selecting any number of prompt-response pairs for inclusion in the blog post
> * Provide an option to view the full prompt before selecting (optional)
> 
> ### Verdict Collection
> * For each selected prompt-response pair:
>     * Display the full prompt and response to the user
>     * Ask if the verdict was "pass" or "failure" with a simple prompt: "Was this a success? (Y/N)"
>     * Store the verdict with the prompt-response pair
> * Format verdicts in the blog post as:
>     * Success: "**Verdict:** ✅ [user comment]"
>     * Failure: "**Verdict:** ❌ [user comment]"
> 
> ### Blog Post Generation
> * Use a template similar to the example blog post (2025-03-27-hadai-day-1.md)
> * Include:
>     * YAML frontmatter with title, date, categories, and tags
>     * Introduction section (can be static or prompt user for input)
>     * Selected prompt-response pairs formatted as in the example:
>         * Prompt in a blockquote with "> **Prompt:**" prefix
>         * Response in a blockquote with "> **Response:**" prefix
>         * Verdict with emoji (✅/❌) and user comment
>     * Conclusion section (can be static or prompt user for input)
> * Generate the post as a Markdown file with naming convention: YYYY-MM-DD-hadai-day-N.md
> * Save to the specified output directory or current directory
> 
> ### Error Handling
> * Gracefully handle invalid or missing history files
> * Allow cancellation at any point in the selection process
> * Handle empty selections (warn user and confirm before proceeding)
> * Validate that the output directory exists and is writable
> 
> ### Additional Features
> * Allow user to edit the prompt/response text before inclusion in the blog
> * Provide a summary of selections before generating the final blog post
> * Option to save selection state for resuming later
> * Support for custom templates with variable substitution
> 
> This refined requirements document provides clearer specifications based on the example blog post format and addresses the questions raised in my previous analysis.
> 
> > Tokens: 4.9k sent, 744 received. Cost: $0.03 message, $0.04 session.


**Verdict:** ✅ While it didn't give me the EXACT requirements I wanted, and it incorrectly called out the format of the history file, it did give me a great template to modify to specify the actual requirements I wanted.

## Requirements V3

After some manual editing here's what I landed on for today.
> 
> # LLM History to Post
> 
> ## High Level Goal
> 
> llm-history-to-post is an application that parses LLM chat logs and creates blog post templates based on user input, following the
> format seen in the example blog post.
> 
> ## Detailed Requirements
> 
> ### CLI Interface
> 
> - The application should be invoked via command line: llm-history-to-post [path-to-history-file]
> - There are no flags specified
> - The input file is stored in ".aider.chat.history.md" which resides in the current directory
> - The output file will be specified as the path content/posts/{year}/{month}/{year}-{month}-{day}-hadai-day-.md
> 
> ### Parsing Chat History
> 
> - Parse a ".aider.chat.history.md" file into an in-memory collection of user prompts and LLM responses
> - The file format contains sections with:
>     - User prompts prefixed with "####"
>     - LLM responses are the gaps in-between prompts
> - Group these prompt-response pairs by day based on timestamps in the file. Each line won't have a timestamp but there will be section headings like "# aider chat started at 2025-03-26 19:18:06"
> - Each day should be identified by a date in the format YYYY-MM-DD
> 
> ### Day Selection
> 
> - Present the user with a numbered list of available days found in the history file
> - Display dates in YYYY-MM-DD format
> - If only one day exists, automatically select it
> - Allow user to select a single day to process
> 
> ### Prompt Selection
> 
> - After day selection, display a multi-select list (using SharpPrompt or similar) of all prompts from that day
> - Show the first 100 characters of each prompt as a preview, with "..." if truncated
> - Allow selecting any number of prompt-response pairs for inclusion in the blog post
> - Provide an option to view the full prompt before selecting (optional)
> 
> ### Verdict Collection
> 
> - For each selected prompt-response pair:
>     - Display the full prompt and response to the user
>     - Ask if the verdict was "pass" or "failure" with a simple prompt: "Was this a success? (Y/N)"
>     - Store the verdict with the prompt-response pair
> - Format verdicts in the blog post as:
>     - Success: "Verdict: ✅ [user comment]"
>     - Failure: "Verdict: ❌ [user comment]"
> 
> ### Blog Post Generation
> 
> - Use a template similar to the example blog post (2025-03-27-hadai-day-1.md)
> - Include:
>     - YAML frontmatter with title, date, categories, and tags
>     - Introduction section (can be static or prompt user for input)
>     - Selected prompt-response pairs formatted as in the example:
>         - Prompt in a blockquote with "> Prompt:" prefix
>         - Response in a blockquote with "> Response:" prefix
>         - Verdict with emoji (✅/❌) and user comment
>     - Conclusion section (can be static or prompt user for input)
>     - Generate the post as a Markdown file with naming convention: YYYY-MM-DD-hadai-day-N.md
> - Save to the specified output directory or current directory
> 
> ### Error Handling
> 
> - Gracefully handle invalid or missing history files
> - Allow cancellation at any point in the selection process
> - Handle empty selections (warn user and confirm before proceeding)
> - Validate that the output directory exists and is writable
> 
> ### Additional Features
> 
> - Support for custom templates with variable substitution

---

This was pretty good progress for today! A lot of my "hour" is spent getting these posts formatted appropriately so I'm looking forward to getting this automated. Let's see how that plays out tomorrow!
